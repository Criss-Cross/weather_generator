---
title: "Rainfall Weather Generator"
author: "Sean Gibbon (19770237), Matthew Johnston (19777775), Mitchell Spencer (19034205), Sidra Nasir (18859261)"
date: "8 June 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
``` 
# Introduction and problem statement:
The purpose of this project is to develop a weather generator for rainfall using the data gathered from the Perth Metro weather station (9225). To do so, we will be using a two-state Markov chain to predict the rainfall occurrences. Since we are creating a weather generator, the distinction must first be made between a 'weather generator' and a 'weather predictor' or forecast. The primary difference between the two is that a weather generator is a stochastic model. 
In other words, the simulated weather sequences produced by our generator will be different to past or future weather predictions or observations made using a forecasting model because our weather generator mimics weather data and is not an accurate prediction of the weather. 
 
In accordance with the literature, in order to increase the accuracy of the model, seasonality (the probability of the tranisiton states) for specific months was taken into consideration. The Log-normal distribution was used in the generator as it produced a very similar shape to the actual data. Following this, we tested our generator by generating an alternative rainfall pattern for 2019 (using the previous decade's rainfall levels as training data) and then compared this result to the actual. We then proceeded to run several statistical tests over this generated year (most notably the wilcoxon signed ranked test) and found our generated year to not be significantly different from the year's actual rainfall levels. Furthermore we tested the model against a different data source to verify its reliability and consistency. Concluding that we were able to create an accurate simulation of rainfall (based on a given data source). 
 

# Literature review:

One of the very early works on probabilistic modelling of rainfall was done by Quetelet in 1852 (Katz, 1985), where he showed that consecutive runs of wet or dry days show persistence. Since then, precipitation has been a topic of intense research as the absence or presence of rainfall can affect a large number of other variables that need to be simulated and modelled for weather. It is vital in areas such as farming, ecosystem, climate change simulations, and other important processes (Wilks and Wilby, 1999).

In this project we will be using a two-state Markov chain to predict the rainfall occurrences and amount for the metropolitan areas in Australia. Before beginning however, note that a weather generator is different to a forecast because it is a stochastic model where the simulated weather sequences will not be expected to be the same as the future or past weather observation made using a forecast. In other words, a weather generator mimics weather data but it never predicts the weather.

In an article published in the quarterly Journal of the Royal Meteorological Society in 1962, Gabriel and Neumann first recognised that the frequency-distributions for wet and dry spells created by that point by Williams (1952) and Longley (1953) could be modelled through a Markov chain. They created a statistical model modelling daily rainfall occurrence in Tel Aviv using a first-order Markov chain probability model, under the assumption that whether it will rain or not on the next day will depend on whether rain occurred on the current day. 
Another study conducted by Chowdhury and Lockart (2017) also proposed using a two-state Markov chain to create a stochastic rainfall model focusing on daily rainfall and employed a gamma distribution to model the amount of rain for “wet” days. The model was run multiple times and calculated the mean and standard deviation of the rainfall amount to generate the expected rainfall, and the occurrence of rainfall were modelled using the Markov chain.

In an article published in the quarterly Journal of the Royal Meteorological Society in 1962, Gabriel and Neumann first recognised that the frequency-distributions for wet and dry spells created by that point by Williams (1952) and Longley (1953) could be modelled through a Markov chain. They created a statistical model modelling daily rainfall occurrence in Tel Aviv using a first-order Markov chain probability model. There model was created such that the probability of whether or not it rained the next day depended on the 'state' of the current day (whether it was dry or wet).

Another one of the earlierst works done on this topic was done by Quetelet in 1852 (Katz, 1985), where he showed that consecutive runs of wet or dry days show persistence. Since then, precipitation has been a topic of intense research as the absence or presence of rainfall can affect a large number of other variables that need to be simulated and modelled for weather. It is vital in areas such as farming, ecosystem, climate change simulations, and other important processes (Wilks and Wilby, 1999).
Markov chains have also been used with semi-parametric models that make use of aggregate conditioning variables that can be chosen, to better represent larger time period monthly and annually occurring rainfall patterns. This is particularly useful, as basic two-state markov models, while accurate for short-term weather conditions, have typically underrepresented the overall variance across month and year-based time periods (Mehrotra & Sharma, 2007). 

As was observed in the rainfall data, rainfall amount for each day appeared to not be independent as would be expected for a typical gamma distribution used for each independent wet day, as larger “strings” of wet days had higher average rainfall amounts compared to single wet day events. A kernel density procedure was performed to better model this rainfall distribution, which introduces Markov first order dependence to the model  for rainfall amounts, and may be applicable for our weather model (Mehrotra & Sharma, 2007). 
It is important to note that the current weather generator distinguishes between rainfall occurrence and rainfall amount. Occurence contains two states - either wet or dry. Rainfall amount on the other hand tries to determine the actual numerical amount of rainfall on wet days and thus needs to be modelled and simulated using other means. This can be done using a variety of statistical distributions, including a Gamma (Thom, 1958; Katz, 1977; Buishand, 1977; 1978; Stern and Coe, 1984; Wilks, 1989; 1992) or Exponential (Ananthakrishnan & Soman, 1989; Rodriguez-Iturbe, Cox & Isham, 1987) distribution. 

The data for use in this project is sourced from the Bureau of Meteorology (BOM).

# Methodology and Data

Weather data was retrieved from the Bureau of Meteorology, for the Perth Metro Station. This source was chosen as the Bureau of Meteorology is an official government source with accurate and extensive data (http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=136&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=009225). This dataset contained measurements from 1993 to 2020, with columns detailing product code, BOM station number, year, month and day, rainfall amount, period over which rainfall was measured, and quality. The product code and station number reference what type of data and the station it was collected from respectively, these have the same values for every entry. Period over which rainfall was measured takes on either a value of 1 day or N/A in the dataset. NA's appear more in earlier years, however there are still 11 occurences after 2010. It is assumed that NA values are actually 1 day as each row represents a day, and no values other than 1 exist. Quality is a categorial variables that takes on either 'Y' or 'N', indicating if the data has been quality controlled, with Y indicating that the observation had completed quality control and acceptable, N indicating that is was not yet completed the quality control process, and quality was not assured. Quality control had not been performed since 2008. Due to the simple nature of the dataset, and the amount of entries we had to work wih, we did not consider that using quality controlled data was important, if there were a few entries of rainfall misrecorded, it would not impact the results much. Even if all of the data was wrong, we could still use it to produce a markov chain and test it against the data. We decided to only use data since 2010, as it would still be a sizeable amount of data, while making it more manageable. Rainfall may have also changed over time due to climate change or rainfall collection methods, so more recent data may be better.

Our methodology is broken down as follows:

1) Data manipulation and gathering
- Modify dataset to calculate transition state probabilities
- Calculate transition state probabilities and average rainfalls by month
- Test rainfall variation by month and year

2) Produce markov chain model
- Generate a wet or dry day depending on previous day and transition state probability for the month
- Generate rainfall amount according to log-normal distribution

3) Testing
- Numerical comparison of rainfall levels between simulated data and actual data
- Wilcoxon signed ranked test and comparison of P-values
- Tested model on secondary data source and compared the respective results to confirm that it 

# Code rationale 
```{r}
# Reading in the data from the csv file
data <-  read.csv("IDCJAC0009_009225_1800_Data.csv")
weather_data <- data
weather_data <- weather_data[which(is.na(weather_data$Rainfall.amount..millimetres.) == FALSE),] # excluding rows with no rainfall record made 
```

```{r}
weather_data$date <- do.call(paste, c(weather_data[c("Day", "Month", "Year")], sep = "-")) # creating a column that contains the date for easy indentification
```
In order to generate a markov chain, we must first calculate the probability of the transition states. Since our data contains the rainfall amounts for each day, we need to convert these into a recording of whether the day was wet or dry, which will refer to as the days 'states', and the state transition, for example, dry state to wet state, in which it did not rain the previous day, and rained on that day. The first thing we did is create a function to classify a day's state as dry if it had <1mm of rainfall, and wet if it has >1mm of rainfall, as per the methodology. This allows us to create a new column in the data for the state depending on the rainfall column. We created a new column in the weather data for the state.
```{r}
# function to categorise day as either 'wet' or 'dry' for the Markov Chain functions
state <- function(x){
  stateList <- c()
  for(ii in 1:length(x)){
    if(x[ii] < 1){
      stateList <- c(stateList, "dry")
    }
    if(x[ii] >= 1){
      stateList <- c(stateList, "wet")
    }
  }
  return(stateList)
}
weather_data$state <- state(weather_data$Rainfall.amount..millimetres.)
```
We can see below what this results in.
```{r}
head(weather_data[,c('Rainfall.amount..millimetres.','state')], 10)
```
Now that we have the state for every observation in the dataset, we can now find the transition states. We do this by looping through the dataset, and record the transition state as the state of the previous observation to the new observation. This results in four possible states: Dry to dry, dry to wet, wet to wet, and wet to dry. The first observation's transition state is not found as there is no state from the day before to calculate it. We then record this as a column of the dataset.
```{r}
# function establishing Markov Chain transition state. Establishing the relationship between the rainfall of a given day and the day before it.
transitionState <- function(x){
  transitionStateList <- c('') #can't find transition state of first observation
  for(i in 2:length(x)){
    if(x[i] == "dry"){
      if (x[i-1] == "dry"){
        transitionStateList <- c(transitionStateList, "DryToDry")
      }
      else {
        transitionStateList <- c(transitionStateList, "WetToDry")
      }
    }
    if(x[i] == "wet"){
      if (x[i-1] == "dry"){
        transitionStateList <- c(transitionStateList, "DryToWet")
      }
      else {
        transitionStateList <- c(transitionStateList, "WetToWet")
      }
    }
  }
  return(transitionStateList)
}
weather_data$transitionState <- transitionState(weather_data$state)
```
The transition states can be seen below.
```{r}
head(weather_data[,c('Rainfall.amount..millimetres.','state', 'transitionState')], 10)
```
Data was restricted from the period of after 2010. Since the main use of the data is to find the probability of the transition states, and average rainfalls for use in the generator later, we did not need a very large amount of data. Reducing this to 10 years gives a large enough data size, while ensuring the data is more accurate to current weather conditions, which is important as they may have differed due to climate change. Recent data may also be more accurate due to better data collection methods. Below we can see how the rainfall varies by each month and year. There is the most rainfall around winter, as expected, and less around summer. We also find that the rainfall per year varies a lot, from around 500ml to over 800ml in 2010 and 2011, respectively. Since the year of 2020 was not complete at the time of data collection, the bar plot for 2020 is not complete.
```{r, warning=FALSE}
train_data <- subset(weather_data, Year >= 2010) # only look at the most recent, relevant data.
library(ggplot2)
library(RColorBrewer)

# explorative plots investigating the distribution of rainfall across months and years

# Plotting the rainfall data (grouped by years and months)
# Distribution of rainfall by month (segmented by year)
ggplot(train_data, aes(x = factor(Month), y = Rainfall.amount..millimetres., fill = factor(Year))) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(palette = "Paired") + 
  xlab("Month")+
  ylab("Rainfall (mm)")+
  labs(fill = "Year")+
  ggtitle("Rainfall of each month. Divided into Years")
# There does appear to be a rough distribution of rainfall by month. Most years May, June, July, August, and September (month 5-9) have the most rain. There are outliers

ggplot(train_data, aes(x = factor(Year), y = Rainfall.amount..millimetres., fill = factor(Month))) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(palette = "Paired") + 
  xlab("Year")+
  ylab("Rainfall (mm)")+
  labs(fill = "Month")+
  ggtitle("Rainfall of each Year. Divided into Months")
# There does not appear to be any obvious pattern in the rainfall across the 10 years (note. 2020 only contains 4 months of data, hence the low rainfall). The average looks to be around 650-700 mm. 
```
```{r}
table(train_data$Month, train_data$Year) # only four months of data in 2020
```
We need to calculate the probabilities of the four transition states in order to make a markov chain to generate weather data. In the first basic model we did this with no respect to month or season, generated overall probabilities. To do this we simply divide the amount of wet to wet transition states by the number of wet to wet plus wet to dry, to find the wet to wet transition probability. We can find find the wet to dry probability as one subtract this probability, as they sum to do. Similarly, we find the probabilities of dry to dry and dry to wet. This ended up being a 0.506 probability of wet to wet, and 0.872 for dry to dry. That is, if it rained the previous day, there is a 50.6% chance it will rain today, and if it did not rain yesterday, a 87.2% chance it will not rain today.
```{r}
#Calculating transition state probabilities, in general (no respect to month or season)
weatherTable <- table(train_data$transitionState)
weatherTable

probWetToWet = weatherTable['WetToWet'] / (weatherTable['WetToWet'] + weatherTable['WetToDry'])
probWetToWet

probDryToDry = weatherTable['DryToDry'] / (weatherTable['DryToDry'] + weatherTable['DryToWet'])
probDryToDry
```
This first basic generator takes an integer for how many days to simulate as input, and returns a list of rainfall amounts for each day. If the current state is dry, then if a random number between 0 and 1, generated by the runif() function, is below the probability of the dry to dry transition state, we keep the current state as dry, if not, we update the state to wet. Similarly, if the current state is wet, we keep it as wet or update it to dry depending on a random chance along with the probability calculated before. If the new state is dry, we record the rainfall as 0ml. If the new state is wet, we generate a random draw from the log-normal distribution as the rainfall amount. The rainfall amount is given by: 5.66*exp(rnorm(1)). We multiply by 5.66 as the expected value of exp(rnorm(1)) is around 1.648, and needs to generate rainfall with the average being the mean of the rainfall of the days when it does rain, which is 9.32ml in this case. 
```{r}
#Basic generator (No seasonal variation)

#calculated above
generateRainfallBasic <- function(genLength){
  currentState = "dry" # Years start with very little rain, so more likely to start dry
  rainAmountList <- c()
  for (i3 in 1:genLength){
    if (currentState == "dry"){
      if (runif(1) < probDryToDry){
        currentState = "dry"
      }
      else{
        currentState = "wet"
      }
    }
    else if (currentState == "wet"){
      if (runif(1) < probWetToWet){
        currentState = "wet"
      }
      else{
        currentState = "dry"
      }
    }
    #generating amount of rainfall if state is wet, else 0
    if (currentState == "wet"){
      rainAmount <- 5.66*exp(rnorm(1))
      rainAmountList <- c(rainAmountList, rainAmount)
    }
    else{
      rainAmountList <- c(rainAmountList, 0)
    }
  }
  return(rainAmountList)
}
```
Log-normal is used as it produces a very similar shape to the actual data. Importantly, it produces some results that are far off the bulk of the data, as found in the actual data. Originally, we used the exponential distribution, which did not produce this. As can be seen, similar means are produced from the simulated and actual rainfall data.
```{r}
#comparing log-normal against actual data, veeerryyyy close fit, will use log-normal for rainfall sim
par(mfrow=c(1,2))
p1 <- 5.66*exp(rnorm(732))
hist(p1, breaks = 30, xlim = c(0,120), ylim = c(0,400), main = "Simulated distribution", xlab = "Rainfall (ml)")

p2 <- train_data$Rainfall.amount..millimetres.[train_data$Rainfall.amount..millimetres.>1]
hist(p2, breaks = 30, xlim = c(0,120), ylim = c(0,400), main = "Actual distribution", xlab = "Rainfall (ml)")

mean(p1)
mean(p2)
```
Testing the basic generator, it appears that the amount of rainfall when it rained approximated the actual case very well. However, comparing 3761 days of simulated rainfall compared to actual rainfall, we can see that the actual rainfall comes more in waves, compared to the simualted rainfall here. This is because it rains more in winter months, meaning that the transition state probabilities are different for each month or season.
```{r, fig.height=8}
#Basic generator tests
testRainfall = generateRainfallBasic(3761)

par(mfrow=c(2,1))
hist(train_data$Rainfall.amount..millimetres.[train_data$Rainfall.amount..millimetres.>1 & train_data$Rainfall.amount..millimetres.<50], xlab = "Actual Rainfall (mm)", main = "Actual Rainfall Frequency Histogram")
hist(testRainfall[testRainfall > 1 & testRainfall <50], xlab = "Simulated Rainfall (mm)", main = "Simulated Rainfall Frequency Histogram")

par(mfrow=c(2,1))
barplot(train_data$Rainfall.amount..millimetres., ylim = c(0,80), main = "Original Data", ylab = "Rainfall (mm)", xlab = "Index")
barplot(testRainfall, ylim = c(0,80), main = "Simulated Data", ylab = "Rainfall (mm)", xlab = "Index")
```
We need to have a way to test how the frequency of raining changes. This function returns a list of how many days between each time it rained.
```{r}
daysBetweenRain <- function(input){
  returnList <- c()
  currentLength <- 0
  for (i in input){
    if (i<1){
      currentLength <- currentLength + 1
    }
    else{
      returnList <- c(returnList, currentLength)
      currentLength <- 0
    }
  }
  return(returnList)
  }
```
We can see below a histogram of days between rainfall. We find that the basic generator differs greatly from the real rainfall, with less on the tail ends of around 0 days and >50 days. This is because a lack of seasonal variability that exists in the real life cases decreases the chances that we will have a long streak, as seen in summer in real life, or a short streak, as common in winter. For an accurate model, we expect that the mean and standard deviation of the two days between rainfall for the real and simulated case be similar.
```{r}
hist(daysBetweenRain(train_data$Rainfall.amount..millimetres.)[train_data$Rainfall.amount..millimetres.>-1], main = "Histogram of days between rainfall (Actual rainfall)", breaks = 100, xlab = "Days between rainfall", ylim = c(0,500))
hist(daysBetweenRain(testRainfall)[daysBetweenRain(testRainfall)>-1], main = "Histogram of days between rainfall (Simulated rainfall)", breaks = 100, xlab = "Days between rainfall", ylim = c(0,500))
```

Therefore, we need to change the probability for the state changes in the generator depending on the month of the year. To do this we created a data frame to count the number of occurences of transition states for each month. We initially filled the data frames all with zeroes, and increased the count by one for every occurence.
We then create a copy of that data frame and calculate the probabilities just as before. This results in a data frame with the transition probabilities for each month.
```{r}
#Calculates the transition probabilities for each month
probTransStatesMonth <- function(input_data){
  transitonStatesMonthsFrame <- data.frame(list(rep(0, 12), list(rep(0, 12), list(rep(0,    12), list(rep(0, 12)))))) #Initialises 12x4 frame filled with zeroes (4 columns for each transition state, 12 rows for each month)
  names(transitonStatesMonthsFrame) <- c('DryToDry', 'DryToWet', 'WetToDry', 'WetToWet')

  #Makes the dataframe with the count of each transition state with each month
  for (i4 in 1:dim(input_data)[1]){
    tempTransitionState <- input_data[i4, 'transitionState']
    tempMonth <- input_data[i4, 'Month'] 
    transitonStatesMonthsFrame[tempMonth, tempTransitionState] <- transitonStatesMonthsFrame[tempMonth, tempTransitionState]+1 # increase count of tempTransitionState for month tempMonth by 1
  }

  #Calculates the transition state probabilities for each month in the data frame
  probTransitonStatesMonthsFrame <- transitonStatesMonthsFrame
  for (i in 1:dim(transitonStatesMonthsFrame)[1]){
  
    probTransitonStatesMonthsFrame[i, 'DryToDry'] <- transitonStatesMonthsFrame[i, 'DryToDry'] / (transitonStatesMonthsFrame[i, 'DryToDry'] + transitonStatesMonthsFrame[i, 'DryToWet'])
  
    probTransitonStatesMonthsFrame[i, 'DryToWet'] <- transitonStatesMonthsFrame[i, 'DryToWet'] / (transitonStatesMonthsFrame[i, 'DryToDry'] + transitonStatesMonthsFrame[i, 'DryToWet'])
    
    probTransitonStatesMonthsFrame[i, 'WetToDry'] <- transitonStatesMonthsFrame[i, 'WetToDry'] / (transitonStatesMonthsFrame[i, 'WetToDry'] + transitonStatesMonthsFrame[i, 'WetToWet'])
    probTransitonStatesMonthsFrame[i, 'WetToWet'] <- transitonStatesMonthsFrame[i, 'WetToWet'] / (transitonStatesMonthsFrame[i, 'WetToDry'] + transitonStatesMonthsFrame[i, 'WetToWet'])
    # this data frame 'probTransitionStatesMonthsFrame' will be called directly in the generator, so must be called as such when exported
  }
  return(probTransitonStatesMonthsFrame)
}
```

```{r}
probTransitonStatesMonthsFrame <- probTransStatesMonth(train_data)
head(probTransitonStatesMonthsFrame, 10)
```
Not only is it more likely to rain in some months than others, but there is also a different average amount of rainfall when it does rain. We tested to see if there's a different average rainfall for wet to wet vs dry to wet transition states, however, the resulting wilcoxon test did not show enough evidence to support this, so it was not added in the final model. A kruskal-wallis test of the average rainfall when it did rain (not total rainfall) for each month revealed sufficient evidence to conclude a difference for the month. The non-parametric tests were used as the rainfall data was not normally distributed.
```{r}
#testing average rainfall when its rains in each month, and for wettowet vs drytowet transitions.
test_w2w <- train_data$Rainfall.amount..millimetres.[train_data$transitionState == "WetToWet"]
test_d2w <- train_data$Rainfall.amount..millimetres.[train_data$transitionState == "DryToWet"]
mean(test_w2w)
mean(test_d2w)
wilcox.test(test_d2w, test_w2w)
#since resulting wilcox test p-value is 0.85, we conclude that theres no difference in rainfall depending on the transition state, and do not need to include it in our model.

test_rainfallPerMonth <- train_data[train_data$state == "wet",c(4,6)]
kruskal.test(Rainfall.amount..millimetres. ~ Month, data = test_rainfallPerMonth)
#p-val = 0.00016, therefore difference between average rainfall for each month

```
The average rainfall when it rained for each month was calculated, to be used in the more advanced generator. This was done by storing rainfall for wet days in a nested list and finding the mean.
```{r}
#calculating the mean rainfall when it rains for each month, to change how much it rains according to the generator later on. Limited to less than 60 mls as the dataset is not large enough for large rainfall amounts (such as 114ml in feburary) to not throw the mean off.
rainMonthData <- c()
for (i in 1:12){
  temp<- train_data$Rainfall.amount..millimetres.[train_data$state == "wet" & train_data$Month == i & train_data$Rainfall.amount..millimetres. < 60]
  rainMonthData <- c(rainMonthData, list(temp))
  rm(temp)
}

rainfallAvgMonth <- sapply(rainMonthData, mean)

```

```{r}
plot(c(1:12), rainfallAvgMonth, type = "l", xlab = "Month", ylab = "Average Rainfall (mm)", main = "Average rainfall for wet days for each month")
```

As can be seen, the transition states vary for each month.
```{r}
#How the transition state probabilities vary for each month
plot(probTransitonStatesMonthsFrame$DryToDry, ylim = c(0,1), xlab = "Month", main = "'dry to dry' transition state probability", type = 'l', ylab = "Probability")
plot(probTransitonStatesMonthsFrame$WetToWet, ylim = c(0,1), xlab = "Month", main = "'wet to wet' transition state probability", type = 'l', ylab = "Probability")
```

The new updated weather generator uses the same old generator code for the most part, with a few changes. We now change the probability of the transitions depending on the month of the observation. This requires that we now input a data frame with a month column to calculate this. The rainfall generated on wet days is also updated to vary per month. 
```{r}
#Weather generator accounting  for seasonal variation of transition states or something i hope
#This is just a regular version of basic generator it's mostly the same in fact if i forget to even do this it is the same

generateRainfallSeasonal <- function(input){
  # input must be weather_data or a subset of weather_data
  currentState = "dry" #can make this into a random choice later
  rainAmountList <- c()
  for (i5 in 1:dim(input)[1]){
    if (currentState == "dry"){
      if (runif(1) < probTransitonStatesMonthsFrame[input[i5, 'Month'], 'DryToDry']){ #now inputs depending on the month of input
        currentState = "dry"
      }
      else{
        currentState = "wet"
      }
    }
    else if (currentState == "wet"){
      if (runif(1) < probTransitonStatesMonthsFrame[input[i5, 'Month'], 'WetToWet']){
        currentState = "wet"
      }
      else{
        currentState = "dry"
      }
    }                                   
    #generating amount of rainfall if state is wet, else 0
    if (currentState == "wet"){
      #rainAmount <- 5.66*exp(rnorm(1)) #now log-normal dist, 5 used because is close to mean of weather_data's / the mean of what exp(rnorm(1)) is by default /// Old Version 
      rainAmount <- rainfallAvgMonth[input[i5, 'Month']]*exp(rnorm(1))/1.648 
      #average of exp(rnorm(1)) is ~1.648, so we divide by that so the average of each month will just be the actual average calculated from rainfallAvgMonth.
      rainAmountList <- c(rainAmountList, rainAmount)
    }
    else{
      rainAmountList <- c(rainAmountList, 0)
    }
  }
  return(rainAmountList)
}
```

```{r}
#testing code for seasonal generator
inputSeasonalRainfall <- dplyr::select(train_data, 'Year', 'Month', 'Day') #using existing train data's dates to input to function, instead of putting in just how many to generate
testSeasonalRainfall = generateRainfallSeasonal(inputSeasonalRainfall)
```
Simulated rainfall now follows a more seasonal pattern, as seen in the original data. Since we have used the original datas transition probabilities and rainfall averages, we expect that our model can give similar results to the original data.
```{r}
plot_seasonal_data <- function(training_data_input,seasoned_data_rainfall, title){
  par(mfrow=c(2,1))
  barplot(training_data_input$Rainfall.amount..millimetres., ylim = c(0,80), main = c("Original Data", title), ylab = "Rainfall (mm)", xlab = "Index")
  barplot(seasoned_data_rainfall, ylim = c(0,80), main = c("Simulated Seasonal Data", title), ylab = "Rainfall (mm)", xlab = "Index")
}
plot_seasonal_data(train_data,testSeasonalRainfall, "(Perth)")
```
Below shows the testing of the days between rainfall for the updated generator. As we can see, the distributions are now much closer than previously, by accounting for seasonal variability. There are now multiple stretches of no rain for more than 50 days, as seen in the actual data. There is also a similar amount of 0 days between rainfall. This is a significant improvement that increases the realisticness of the results.
```{r}
hist(daysBetweenRain(train_data$Rainfall.amount..millimetres.)[train_data$Rainfall.amount..millimetres.>-1], main = "Histogram of days between rainfall (Actual rainfall)", breaks = 100, xlab = "Days between rainfall", ylim = c(0,500))
hist(daysBetweenRain(testSeasonalRainfall)[daysBetweenRain(testSeasonalRainfall)>-1], main = "Histogram of days between rainfall (Simulated rainfall)", breaks = 100, xlab = "Days between rainfall", ylim = c(0,500))
```
We see that a wilcoxon test reveals no evidence to suggest that the medians of the simulated and actual days between rainfall are different. The means and standard deviations are also similar. Therefore, this model accurately generates rainfall generator according to this parameter.
```{r}
wilcox.test(daysBetweenRain(testSeasonalRainfall), daysBetweenRain(train_data$Rainfall.amount..millimetres.))
mean(daysBetweenRain(testSeasonalRainfall)); mean(daysBetweenRain(train_data$Rainfall.amount..millimetres.))
sd(daysBetweenRain(testSeasonalRainfall)); sd(daysBetweenRain(train_data$Rainfall.amount..millimetres.))
```


```{r}
#comparing log-normal against actual data, veeerryyyy close fit, will use log-normal for rainfall sim
p1 <- 5.66*exp(rnorm(732))
p1 <- p1[p1>1]
hist(p1, breaks = 30, xlim = c(0,120), ylim = c(0,400), main = "Simulated distribution")

p2 <- train_data$Rainfall.amount..millimetres.[train_data$Rainfall.amount..millimetres.>1]
hist(p2, breaks = 30, xlim = c(0,120), ylim = c(0,400), main = "actual distribution")
```

## Testing with sampling - Testing on a percentage of the data

To properly test a predictive algorithm, you cannot test the algorithm on the data that you trained it on. In a practical application, the algorithm would be predicting events that have not yet transpired, so would need to train on data from the past. To test the predictive power of the generator, we split 10.5 years of weather data (2010 - 2020) into two groups through random sampling, a training set (80%) and a testing set (20%). The training data was used to retrain the seasonal generator, entailing calculating new probabilities of transitioning between states for each month, and calculating the mean rainfall for each month. As the generator was retrained on only a portion of the data, it can be tested on the remainder 

```{r}
set.seed(100345)
sampID <- sample.int(nrow(train_data), size = 0.8*nrow(train_data), replace = FALSE)
train_data <- train_data[sampID,] # 80% of data for training
test_data <- train_data[-sampID,] # 20% for testing
```

```{r}
probTransitonStatesMonthsFrame <- probTransStatesMonth(train_data) # retraining seasonal generator probTransitionStatesMonthsFrame with new training data (now only 80% of the original train_data)
# calucating the new average rainfall for each month
rainMonthData <- c()
for (i in 1:12){
  temp<- train_data$Rainfall.amount..millimetres.[train_data$state == "wet" & train_data$Month == i & train_data$Rainfall.amount..millimetres. < 60]
  rainMonthData <- c(rainMonthData, list(temp))
  rm(temp)
}
rainfallAvgMonth <- sapply(rainMonthData, mean)
```

The newly calibrated seasonal generator was then used to predict the testing data. This just involved generating simulated rainfall with the same number of observations as the tesing data (about 2.6 years of rainfall, or 20% of the original 10.5 years)

```{r}
#generates a simulation with the same number of observations as test_data (20% of the total data)
testSeasonalRainfall20 = generateRainfallSeasonal(test_data) 
```

```{r}
par(mfrow = c(2, 1))
barplot(testSeasonalRainfall20, ylab = "Rainfall (mm)", xlab = "index", main = "Simulated data")
barplot(test_data$Rainfall.amount..millimetres., ylab = "Rainfall (mm)", xlab  = "index", main = "Actual data")
```
```{r}
# Wilcoxon signed rank test
WT <- wilcox.test(testSeasonalRainfall20, test_data$Rainfall.amount..millimetres., paired=T)
print("Wilcoxon rank sum p-value")
WT$p.value
# paired student t test
TT <- t.test(testSeasonalRainfall20, test_data$Rainfall.amount..millimetres., paired=T)
print("t-test p-value")
TT$p.value
```
Looking at the barplots of the simulated data (top) and the actual data (bottom), the two do not appear to be similar. While the simulation looks believeable, random with periods of intense rainfall, it does not resemble the actual data specifically. To test the similarity of the two data sets, both the non-parametric Wilcoxon Signed Rank Test and the parametric Student T Test were performed. Both tests are paired as each simulated day is attempting to predic a specific actual day. A non-parametric test was used in conjunction with a parametric test as from the distribution of the rainfall is not normal (as seen by earlier histograms). Both tests returned a p-value less than 0.005 at a significance of 0.05, and as such it can be concluded that the simulated rainfall and the actual rainfall are different. 

## Using the data from the previous 10 years (2009-2018) to predict the weather for the next year (2019)

Predicting a randomly selected 20% of the weather data was unsuccesful, the simulated data and the actual data were significantly different, and by a comfortable margin. To try to increase the accuracy of the simulated data, we will increase the amount of training data and attempt to predict a specific year, instead of a randomly selected bunch of days. Increasing the amount of training data should increase the accuracy of the probabilites, and reduce the impact of outlying observation; and predicting a specific year should give the seasonal function of the generator more power. The next test will be predicting the rainfall of 2019 using 10 years of data from 2009-2018. To achieve this, the seasonal generator was retrained on all the rainfall data from those 10 years, and a simulation the lengh of one, non leap, year was generated. 

```{r}
train_data <- subset(weather_data, Year >= 2010)
train10_data <- subset(weather_data, Year >= 2009 & Year < 2019)
data_2019 <- subset(weather_data, Year == 2019)
```

```{r}
probTransitonStatesMonthsFrame <- probTransStatesMonth(train10_data) # retraining seasonal generator probTransitionStatesMonthsFrame with train10_data
set.seed(10356)
monthList <- subset(weather_data, Year == 2019) # a year that isn't a leap year to get the month list, as generation algorithm only requires months
monthList <- monthList['Month']
testSeasonalRainfall10 <- generateRainfallSeasonal(monthList)
```

```{r, fig.height=9}
#compare generated year against 2019
par(mfrow = c(2,1))
barplot(testSeasonalRainfall10, xlab = "Index", ylab = "Rainfall (mm)", main = "Simulated Rainfall")
barplot(data_2019$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2019 Rainfall")
```
Looking at the simulated rainfall against the actual 2019 rainfall, the simulation has a very similar wet dry cycle, that is the length and timing of the extended wet and dry states, to the actual data, even if the amount of rainfall during the wet seasons is not an accurate depiction. Aside from the exact amount of rain, the simulation looks to be a fairly good prediction of 2019. 

To check if the simulated year is a good prediction of 2019 specifically, we plotted it against several years that were used to train it. As the simulation was created using data from those years, it should show some resemblance, but if the simulated rainfall is predcintg 2019 specifically, the similarity should be less distinct.
```{r}
# check other years for comparison
par(mfrow = c(3,2))
barplot(testSeasonalRainfall10, xlab = "Index", ylab = "Rainfall (mm)", main = "Simulated Rainfall")
year <- subset(weather_data, Year == 2015)
barplot(year$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2015 Rainfall")
year <- subset(weather_data, Year == 2008)
barplot(year$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2008 Rainfall")
year <- subset(weather_data, Year == 2015)
barplot(year$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2017 Rainfall")
year <- subset(weather_data, Year == 2007)
barplot(year$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2007 Rainfall")
year <- subset(weather_data, Year == 2013)
barplot(year$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2013 Rainfall")
rm(year)
```
As shown by the plots above, the simulated rainfall is roughly similar to other years, particularly 2007 and 2013 which have a similar wet dry cycle. However, the similarity does not appear to be as distinct, at least visually.

## Examining for patterns

So far, our generator utilised a two-state Markov chain based on whether a day was wet or dry. The simulations seem to be accurate, at least in regards to the wet dry cycle, but there is still definite room for improvement. A possible avenue for improvement is investigating if there are consistent patterns at larger time intervals, such as weeks. If such patterns are present they could guide the total volume of rainfall for that time period or be an additional layer of Markov Chain to standardise or correct the first, that is based on days. Rainfall by weeks will be explored first. 
```{r}
# Creates a graph of difference in rainfall for years, weeks, months, years to see if there are any potential patterns.
# Creates a list of the weekly rainfall
RainfallWeekly <- data.frame("Rainfall (mm)", "Week")
colnames(RainfallWeekly) <- c("Rainfall (mm)", "Week")
RainfallWeekly$`Rainfall (mm)` <- as.numeric(RainfallWeekly$`Rainfall (mm)`)
RainfallWeekly$Week <- as.numeric(RainfallWeekly$Week)
week = 1
weekRain = 0
for(ii in c(1: nrow(weather_data))){
  weekRain = weekRain + weather_data[ii, 6] # rainfall amount for that row
  
  if(ii%%7 == 0){ # every 7th row
    RainfallWeekly[(ii/7), 1] <- weekRain # 1 row of RainfallWeekly created every 7 rows (1 weeks) - inserting rainfall total for that week
    RainfallWeekly[(ii/7), 2] <- week
    week = week + 1
    weekRain = 0 # clear total rainfall to prepare for next week
  }
}
```

```{r}
RainfallWeeklyDiff <- data.frame(c(1:(nrow(RainfallWeekly)-1)), c(1:(nrow(RainfallWeekly)-1))) # data frame with two columns, one less row than RainfallWeekly
colnames(RainfallWeeklyDiff) <- c("Rainfall diff (mm)", "Week")
RainfallWeeklyDiff$`Rainfall diff (mm)` <- diff(RainfallWeekly$`Rainfall (mm)`) # change in weeks
```

```{r, fig.height= 14}
# plot first 700 weeks first against the difference in rainfall, and then the rainfall per week
par(mfrow = c(4,1))
plot(RainfallWeeklyDiff[c(1:350), 2], RainfallWeeklyDiff[c(1:350), 1], xlab = "week", ylab = "change in rainfall (mm)", cex = 2, type = "b", main = "Difference in rainfall (mm) by week")
plot(RainfallWeekly[c(1:350), 2], RainfallWeekly[c(1:350), 1], xlab = "week", ylab = "rainfall (mm)", type = "l", main = "Rainfall (mm) by week")
plot(RainfallWeeklyDiff[c(351:700), 2], RainfallWeeklyDiff[c(351:700), 1], xlab = "week", ylab = "change in rainfall (mm)", cex = 2, type = "b", main = "Difference in rainfall (mm) by week")
plot(RainfallWeekly[c(351:700), 2], RainfallWeekly[c(351:700), 1], xlab = "week", ylab = "rainfall (mm)", type = "l", main = "Rainfall (mm) by week")
```

Looking at the plot of the rainfall amount of rainfall by week, there seems to be fairly consistent periods of rainfall followed by dryness, with similar amounts of rainfall. However, looking at the plot of the difference in rainfall by week, it can be seen that the amount of rainfall in the wet periods are not consistent, with some having consistent rainfall (shown as small spikes) and others quickly changing between heavy rainfall and light rain (large spikes). Overall, the inconsistency of the amount of rainfall in wet periods, and the variation, though not large, in the time between wet and dry periods does not warrant the addition of a weekly Markov chain.

```{r, fig.height= 14}
# might remove this, already show first 700 weeks

# plot second 700 weeks first against the difference in rainfall, and then the rainfall per week
par(mfrow = c(4,1))
plot(RainfallWeeklyDiff[c(701:1050), 2], RainfallWeeklyDiff[c(701:1050), 1], xlab = "week", ylab = "change in rainfall (mm)", cex = 2, type = "b")
plot(RainfallWeekly[c(701:1050), 2], RainfallWeekly[c(701:1050), 1], xlab = "week", ylab = "rainfall (mm)", type = "l")
plot(RainfallWeeklyDiff[c(1051:1414), 2], RainfallWeeklyDiff[c(1051:1414), 1], xlab = "week", ylab = "change in rainfall (mm)", cex = 2, type = "b")
plot(RainfallWeekly[c(1051:1414), 2], RainfallWeekly[c(1051:1414), 1], xlab = "week", ylab = "rainfall (mm)", type = "l")
```

In order to quantify the accuracy of our generator, we will use statistical tests. The test would be a paired two sample test, as each day in the simulated data corresponds to a specific day in the actual day. Two candidates that meet that crteria are a paired two sample Student T test and the Wilcoxon Signed Rank test. The former is a parametric test, while the latter is non-parametric. To decide between the two, we looked at the normality of the data, as parametric tests are often more accurate than non-parametric if the data is normally distributed. 
```{r}
rainSort_2019 <- data_2019$Rainfall.amount..millimetres.
# qqplot before removing 'dry' days
par(mfrow=c(1,2))
qqnorm(rainSort_2019, pch = 1, frame = F, main = "Normal Q-Q Plot of Rainfall 2019 (including dry days)")
qqline(rainSort_2019, col = "red", lwd = 2)
rainSort_2019 <- rainSort_2019[which(rainSort_2019 != 0)]
# qqplot after removing 'dry' days
qqnorm(rainSort_2019, pch = 1, frame = F, main = "Normal Q-Q Plot of Rainfall 2019 (excluding dry days)")
qqline(rainSort_2019, col = "red", lwd = 2)

# data is not normally distributed
rm(rainSort_2019)
```
From the above qq-plots, it is clear that the data is not normally distributed, whether we include or exclude dry days. Thus, we will use the non-parametric Wilcoxon Signed Rank test to check the similarity between the simualted rainfall for 2019 and the actual rainfall.

## Wilcoxon signed rank test on the data for 2019
```{r}
# Function that returns the sum of ranks of difference (w+ and w-) that are part of the Wilcoxon signed rank calculations
returnRanks <- function(simulated, actual){
  diffs <- (simulated - actual)
  diffs <- diffs[diffs != 0]
  posDifs <- which(diffs > 0)
  negDiffs <- which(diffs < 0)
  rank <- rank(abs(diffs))
  rankPosDiff <- sum(rank[posDifs])
  rankNegDiff <- sum(rank[negDiffs]) 
  return(c(rankPosDiff, rankNegDiff))
}

```


To get more detailed information about the accuracy of our data, two function were written. The first function partially performs the test, calculating the sum of the ranks of the positive and negative differences. These two numbers tell us how often, and by how much, the generator overestimated and underestimated the rainfall. For example, a large sum of ranks of positive differences indicates that the generator frequently overshot the actual data and/or overshot by a large margin. The second function performs the actual Wilcoxon Signed Rank test, returning the p-value, a 95% confidence interval, and the two sum of ranks that were calculated in the first function.

```{r}
wilcox <- function(seed, year){
  set.seed(seed)
  rainYear <- subset(weather_data, Year == year) # a year that isn't a leap year to get the month list, as generation algorithm only requires months
  monthList <- rainYear['Month']
  simRainfall <- generateRainfallSeasonal(monthList)

  # test of testSeasonalRainfall10 against 2019 rainfall (testSeasonalRainfall10 was simulation of 2019 rainfall)
  print(wilcox.test(rainYear$Rainfall.amount..millimetres., simRainfall, paired = T, alternative = "t", conf.int = T, conf.level = 0.95))
  WP <- wilcox.test(rainYear$Rainfall.amount..millimetres., simRainfall, paired = T, alternative = "t", conf.int = T, conf.level = 0.95)
  cat("P-value is",WP$p.value,"\n")

  # manual calculation of Wilcoxon signed rank values 

  sumRanks <- returnRanks(simRainfall, rainYear$Rainfall.amount..millimetres.)
  cat(sumRanks[1], "is the sum of the ranks of the positive differences","\n")
  cat(sumRanks[2], "is the sum of the ranks of the negative differences","\n")

}
wilcox(404567, 2019)
```

Running the test on the 2019 rainfall and a simulated 2019 rainfall gave a p-value of 0.0402. This is less than the significance level of 0.05, and this it can be consluded that the two are different. Looking at the sum of ranks of differences, the simulation significantly overestimated, as there are far more positive differences. However, the p-value is only just under the 0.05 level of significance.

To confirm the results of the first Wilcoxon Signed Rank test, we repeat the code and test above with 3 different sets of randomised simulated rainfall.

```{r, echo=FALSE}
wilcox(12345, 2019)
wilcox(347876, 2019)
wilcox(3456789, 2019)
```
All three of these tests returned p-values of over 0.05, indicating that the simulated data and the actual data were not significantly different. The highest p-value was 0.8821, and that same test also had the closest positive and negative sum of rank of differences, meaning that the simulation did not consistently over or under shoot, but it's days were spread equally above and below the actual data. 

Given that three out of the four tests performed 


```{r}
# looking at the four total simulations created, there is generally no significant different between the simulated rainfall and the actual rainfall. 
# However looking at rankPosDiff and rankNegDiff calculated for each (the sum of the ranks of the positive and negative differences between the simulated and actual data respectively), the simulated rainfall was consistently larger than the actual data 
# The reason for this is likely because 2019 had a very small amount of rainfall compared to the rest of the years.

```

```{r}
rain2019 <- subset(weather_data, Year == 2019)
simRainfall2019 <- generateRainfallSeasonal(rain2019)
cat(median(simRainfall2019), "is the simulated median \n")
cat(median(rain2019$Rainfall.amount..millimetres.), "is the actual median \n")

cat(sum(train10_data$Rainfall.amount..millimetres.)/10, "is the average total rainfall per year for 2009 to 2018 \n") #/10 to get average of 10 years of rain data
cat(sum(rain2019$Rainfall.amount..millimetres.), "is the total rainfall of 2019 \n")

# given the number of dry days, it makes sense that the median's would be very similar in the Wilcoxon Signed Rank test
# To perform the Wilcoxon Signed Rank test we remove those dates from testSeasonalRainfall10
# 2019 is a non leap year so February will have 28 days
#October 5th and December 19th are missing, so we remove them

# Test of simRainfall2019 against 2019 rainfall (testSeasonalRainfall10 was simulation of 2019 rainfall)
wilcox.test(simRainfall2019, rain2019$Rainfall.amount..millimetres., paired = T, alternative = "t")

# Since the p-value is relatively high, it can be concluded that there is no significant diference between the simulated 2019 data and the actual 2019 data. 
# While the simulation may not be an accurate prediction of 2019 (as seen in the barplots), the simulation was also not logically flawed, as there is not a significant difference between the median of the simulation and the median of the actual.
#Furthermore, a qucik comparison of the medians in the Wilcoxon Signed Rank test shows that (as expected) they are also very similar.
cat("Median of actual and simulated rainfall respectively:", median(rain2019$Rainfall.amount..millimetres.),",", median(simRainfall2019))
rm(simRainfall2019)
```

```{r}
# looking at 2013 data (which had a larger than average amount of rain)
rain2013 <- subset(weather_data, Year == 2013)
monthList <- subset(weather_data, Year == 2013) # A year that isn't a leap year to get the month list, as generation algorithm only requires months
monthList <- monthList['Month']
simRainfall2013 <- generateRainfallSeasonal(monthList)
wilcox.test(simRainfall2013, rain2013$Rainfall.amount..millimetres., paired = T, conf.int = T, conf.level = 0.95)

par(mfrow = c(2,1))
barplot(simRainfall2013, xlab = "Index", ylab = "Rainfall (mm)", main = "Simulated Rainfall")
barplot(rain2013$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2013 Rainfall")

diffs <- (simRainfall2013 - rain2013$Rainfall.amount..millimetres.)
diffs <- diffs[diffs != 0]
posDifs <- which(diffs > 0)
negDiffs <- which(diffs < 0)
rank <- rank(abs(diffs))
rankPosDiff <- sum(rank[posDifs])
rankNegDiff <- sum(rank[negDiffs]) 

rankPosDiff
rankNegDiff
mean(diffs)
```
The following shows the results of our model using a secondary data source from Sydney.
```{r}
# Reading in the data from the csv file for the Sydney Location
data2 <-  read.csv("IDCJAC0009_066062_1800_Data.csv")
weather_data2 <- subset(data2, Year >= 1993)

weather_data2 <- weather_data2[which(is.na(weather_data2$Rainfall.amount..millimetres.) == FALSE),] #excluding rows with no rainfall record made
weather_data2$date2 <- do.call(paste, c(weather_data2[c("Day", "Month", "Year")], sep = "-")) #creating a column that contains the date for easy indentification
weather_data2$state <- state(weather_data2$Rainfall.amount..millimetres.)
weather_data2$transitionState <- transitionState(weather_data2$state)
train_data2 <- subset(weather_data2, Year >= 2010)
inputSeasonalRainfall2 <- dplyr::select(train_data2, 'Year', 'Month', 'Day')
```
```{r}
train_data2 <- subset(weather_data2, Year >= 2010)
train10_data2 <- subset(weather_data2, Year >= 2009 & Year < 2019)
data_2019_2 <- subset(weather_data2, Year == 2019)

probTransitonStatesMonthsFrame <- probTransStatesMonth(train10_data2) # retraining seasonal generator probTransitionStatesMonthsFrame with train10_data
testSeasonalRainfall2 = generateRainfallSeasonal(inputSeasonalRainfall2)
plot_seasonal_data(train_data2,testSeasonalRainfall2, "(Sydney)")
```

```{r}
probTransitonStatesMonthsFrame <- probTransStatesMonth(train10_data2) # retraining seasonal generator probTransitionStatesMonthsFrame with train10_data
set.seed(10546)
monthList_2 <- data_2019_2 # a year that isn't a leap year to get the month list, as generation algorithm only requires months
monthList_2 <- monthList_2['Month']
testSeasonalRainfall10_2 <- generateRainfallSeasonal(monthList_2)
```

```{r, fig.height=9}
#Compare Generated year against 2019
par(mfrow = c(2,1))
barplot(testSeasonalRainfall10, xlab = "Index", ylab = "Rainfall (mm)", main = "Simulated Rainfall")
barplot(data_2019$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2019 Rainfall")
# Conclusion and summary of the findings:
```

In brief, our findings indicate that the simulated weather created by our generator is not statistically different from the actual rainfall data. More specifically, since our p-values are relatively high, this indicates that there is no statistically signficant difference between our generated results and the actual results. Despite the results not being a completely accurate prediction of 2019 (as seen in the bar plots above), the simulation both follows an accurate distribution of rainfall and has a median that is similar to the acutal rainfall. 

# References:

Gabriel, K.R. and Neumann, J. (1962), A Markov chain model for daily rainfall occurrence at Tel Aviv. Q.J.R. Meteorol. Soc., 88: 90-95. doi:10.1002/qj.49708837511.  

Miller, D. K. and Homan, S. M. (1994), Determining Transition Probabilities: Confusion and Suggestions. Medical Decision Making., 14: 52-58. 

Wilks, D. S and Wilby, R. L. (1999), The Weather generation game: a review of stochastic weather models. Progress in Physical Geography., 23: 329-357. 

George, Jany, J. Letha, and P. Jairaj. "Daily rainfall prediction using generalized linear bivariate model–A case study." Procedia Technology 24 (2016): 31-38.

Link to main data source - Perth Metro Weather Station (weather station 009225): 
http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=136&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=009225

Link to secondary data source - Sydney Observatory Hill Weather Station (weather station 66062):
http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=136&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=066062
