---
title: "Weather Generator"
author: "Sean Gibbon (19770237), Matthew Johnston (19777775), Mitchell Spencer (19034205), Sidra Nasir (18859261)"
date: "8 June 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
``` 
# Problem statement and background:
 

# Brief literature review:

One of the very early works on probabilistic modelling of rainfall was done by Quetelet in 1852 (Katz, 1985), where he showed that consecutive runs of wet or dry days show persistence. Since then, precipitation has been a topic of intense research as the absence or presence of rainfall can affect a large number of other variables that need to be simulated and modelled for weather. It is vital in areas such as farming, ecosystem, climate change simulations, and other important processes (Wilks and Wilby, 1999).

In this project we will be using a two-state Markov chain to predict the rainfall occurrences and amount for the metropolitan areas in Australia. Before beginning however, note that a weather generator is different to a forecast because it is a stochastic model where the simulated weather sequences will not be expected to be the same as the future or past weather observation made using a forecast. In other words, a weather generator mimics weather data but it never predicts the weather.

In an article published in the quarterly Journal of the Royal Meteorological Society in 1962, Gabriel and Neumann first recognised that the frequency-distributions for wet and dry spells created by that point by Williams (1952) and Longley (1953) could be modelled through a Markov chain. They created a statistical model modelling daily rainfall occurrence in Tel Aviv using a first-order Markov chain probability model, under the assumption that whether it will rain or not on the next day will depend on whether rain occurred on the current day. 
Another study conducted by Chowdhury and Lockart (2017) also proposed using a two-state Markov chain to create a stochastic rainfall model focusing on daily rainfall and employed a gamma distribution to model the amount of rain for “wet” days. The model was run multiple times and calculated the mean and standard deviation of the rainfall amount to generate the expected rainfall, and the occurrence of rainfall were modelled using the Markov chain.

Markov chains have also been used with semi-parametric models that make use of aggregate conditioning variables that can be chosen, to better represent larger time period monthly and annually occurring rainfall patterns. This is particularly useful, as basic two-state markov models, while accurate for short-term weather conditions, have typically underrepresented the overall variance across month and year-based time periods (Mehrotra & Sharma, 2007). 

As was observed in the rainfall data, rainfall amount for each day appeared to not be independent as would be expected for a typical gamma distribution used for each independent wet day, as larger “strings” of wet days had higher average rainfall amounts compared to single wet day events. A kernel density procedure was performed to better model this rainfall distribution, which introduces Markov first order dependence to the model  for rainfall amounts, and may be applicable for our weather model (Mehrotra & Sharma, 2007). 

It is important to note that the current weather generator distinguishes between rainfall occurrence and rainfall amount. Occurence contains two states - either wet or dry. Rainfall amount on the other hand tries to determine the actual numerical amount of rainfall on wet days and thus needs to be modelled and simulated using other means. This can be done using a variety of statistical distributions, including a Gamma (Thom, 1958; Katz, 1977; Buishand, 1977; 1978; Stern and Coe, 1984; Wilks, 1989; 1992) or Exponential (Ananthakrishnan & Soman, 1989; Rodriguez-Iturbe, Cox & Isham, 1987) distribution. For the current study, both distributions were run and examined using diagnostic tests. 

The data for use in this project is sourced from the Bureau of Meteorology (BOM).

#### Critical Analysis
The Markov chain probabilities for continued rain can be used to “modify” or add a constant to predicted rainfall. Looking at the rainfall data, longer successive periods of rain have higher average rainfalls per day for the period, and so using the higher chance of rain for the next day (modified) to also add a modifier to the predicted amount of rainfall may be useful. As was performed by Mehrotra and Sharma (Mehrotra & Sharma, 2007), it may be useful to modify it to a semi-parametric model, and include aggregate conditioning variables to better model the longer scale monthly and yearly weather conditions, and make use of kernel density procedures to better model the likely non-independent wet days and their corresponding rainfall amounts.

####References:

Gabriel, K.R. and Neumann, J. (1962), A Markov chain model for daily rainfall occurrence at Tel Aviv. Q.J.R. Meteorol. Soc., 88: 90-95. doi:10.1002/qj.49708837511.  

Miller, D. K. and Homan, S. M. (1994), Determining Transition Probabilities: Confusion and Suggestions. Medical Decision Making., 14: 52-58. 

Wilks, D. S and Wilby, R. L. (1999), The Weather generation game: a review of stochastic weather models. Progress in Physical Geography., 23: 329-357. 

####Methodology and Data

#####Our initial methodology can be reduced down to 3 Areas for Weather Modelling:
1. Produce markov chain model on overall data
2. Split data based on Wet vs Dry Seasons
3. Split data based on Seasons


#####Overall Methodology:

1. Data Cleaning:
- Deleting a few extra columns not required for analysis.
- Ensure a consistent number of seasons are present


2. Precipitation Presence:

EDA:
- Producing boxplots to compare between different seasons.
- Producing Spell length distribution.
- Producing Image plots.

Main:

Markov Chain:
- Assigning 1 to days with rainfall greater than 1mm, and 0 otherwise.
- Use rmarkovchain package to construct the transition matrix.

Spell Length:
- The days before transition 
- Calculated using interarrival function.
- Apply QQ diagnostic plots to compare simulated spell length to actual spell length shown in the dataset.


3. Rainfall amount:

Note that this follows the literature of "Daily Rainfall Prediction using Generalized Linear Bivariate Model - A Case Study".

EDA
- Create vector of summed rainfall.
- Create new variables to store overall amounts of rainfall for actual dataset and simulated.
- Produce more EDA for rainfall distribution amounts using line plots.
- Also graph the total yearly rainfall.
- Plot aggregates of the simulated rainfall amounts against the actual rainfall amounts.

Main
- Produce boxplots for each simulated rainfall amount per season. 
- Also produce boxplots for actual dataset. 
- Show simulated boxplots and actual boxplots side by side to see how well the markov chain simulated the overall amount of rainfall for each season. 


 

Link to data source: 
http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=136&p_display_type=dailyDataFile&p_startYear=2019&p_c=-17059101&p_stn_num=009225

# Preliminary Setup 
```{r}
# Reading in the data from the csv file
data <-  read.csv("IDCJAC0009_009225_1800_Data.csv")
weather_data <- data
weather_data <- weather_data[which(is.na(weather_data$Rainfall.amount..millimetres.) == FALSE),] # excluding rows with no rainfall record made 
```

```{r}
weather_data$date <- do.call(paste, c(weather_data[c("Day", "Month", "Year")], sep = "-")) # creating a column that contains the date for easy indentification
```
#Code rationale
In order to generate a markov chain, we must first calculate the probability of the transition states. Since our data contains the rainfall amounts for each day, we need to convert these into a recording of whether the day was wet or dry, which will refer to as the days 'states', and the state transition, for example, dry state to wet state, in which it did not rain the previous day, and rained on that day. The first thing we did is create a function to classify a day's state as dry if it had <1mm of rainfall, and wet if it has >1mm of rainfall, as per the methodology. This allows us to create a new column in the data for the state depending on the rainfall column. We created a new column in the weather data for the state.
```{r}
# function to categorise day as either 'wet' or 'dry' for the Markov Chain functions
state <- function(x){
  stateList <- c()
  for(ii in 1:length(x)){
    if(x[ii] < 1){
      stateList <- c(stateList, "dry")
    }
    if(x[ii] >= 1){
      stateList <- c(stateList, "wet")
    }
  }
  return(stateList)
}
weather_data$state <- state(weather_data$Rainfall.amount..millimetres.)
```
We can see below what this results in.
```{r}
head(weather_data[,c('Rainfall.amount..millimetres.','state')], 10)
```
Now that we have the state for every observation in the dataset, we can now find the transition states. We do this by looping through the dataset, and record the transition state as the state of the previous observation to the new observation. This results in four possible states: Dry to dry, dry to wet, wet to wet, and wet to dry. The first observation's transition state is not found as there is no state from the day before to calculate it. We then record this as a column of the dataset.
```{r}
# function establishing Markov Chain transition state. Establishing the relationship between the rainfall of a given day and the day before it.
transitionState <- function(x){
  transitionStateList <- c('') #can't find transition state of first observation
  for(i in 2:length(x)){
    if(x[i] == "dry"){
      if (x[i-1] == "dry"){
        transitionStateList <- c(transitionStateList, "DryToDry")
      }
      else {
        transitionStateList <- c(transitionStateList, "WetToDry")
      }
    }
    if(x[i] == "wet"){
      if (x[i-1] == "dry"){
        transitionStateList <- c(transitionStateList, "DryToWet")
      }
      else {
        transitionStateList <- c(transitionStateList, "WetToWet")
      }
    }
  }
  return(transitionStateList)
}
weather_data$transitionState <- transitionState(weather_data$state)
```
The transition states can be seen below.
```{r}
head(weather_data[,c('Rainfall.amount..millimetres.','state', 'transitionState')], 10)
```
Data was restricted from the period of after 2010. Since the main use of the data is to find the probability of the transition states, and average rainfalls for use in the generator later, we did not need a very large amount of data. Reducing this to 10 years gives a large enough data size, while ensuring the data is more accurate to current weather conditions, which is important as they may have differed due to climate change. Recent data may also be more accurate due to better data collection methods. Below we can see how the rainfall varies by each month and year. There is the most rainfall around winter, as expected, and less around summer. We also find that the rainfall per year varies a lot, from around 500ml to over 800ml in 2010 and 2011, respectively. Since the year of 2020 was not complete at the time of data collection, the bar plot for 2020 is not complete.
```{r, warning=FALSE}
train_data <- subset(weather_data, Year >= 2010) # only look at the most recent, relevant data.
library(ggplot2)
library(RColorBrewer)

# explorative plots investigating the distribution of rainfall across months and years

# Plotting the rainfall data (grouped by years and months)
# Distribution of rainfall by month (segmented by year)
ggplot(train_data, aes(x = factor(Month), y = Rainfall.amount..millimetres., fill = factor(Year))) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(palette = "Paired") + 
  xlab("Month")+
  ylab("Rainfall (mm)")+
  labs(fill = "Year")+
  ggtitle("Rainfall of each month. Divided into Years")
# There does appear to be a rough distribution of rainfall by month. Most years May, June, July, August, and September (month 5-9) have the most rain. There are outliers

ggplot(train_data, aes(x = factor(Year), y = Rainfall.amount..millimetres., fill = factor(Month))) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(palette = "Paired") + 
  xlab("Year")+
  ylab("Rainfall (mm)")+
  labs(fill = "Month")+
  ggtitle("Rainfall of each Year. Divided into Months")
# There does not appear to be any obvious pattern in the rainfall across the 10 years (note. 2020 only contains 4 months of data, hence the low rainfall). The average looks to be around 650-700 mm. 
```
```{r}
table(train_data$Month, train_data$Year) # only four months of data in 2020
```
We need to calculate the probabilities of the four transition states in order to make a markov chain to generate weather data. In the first basic model we did this with no respect to month or season, generated overall probabilities. To do this we simply divide the amount of wet to wet transition states by the number of wet to wet plus wet to dry, to find the wet to wet transition probability. We can find find the wet to dry probability as one subtract this probability, as they sum to do. Similarly, we find the probabilities of dry to dry and dry to wet. This ended up being a 0.506 probability of wet to wet, and 0.872 for dry to dry. That is, if it rained the previous day, there is a 50.6% chance it will rain today, and if it did not rain yesterday, a 87.2% chance it will not rain today.
```{r}
#Calculating transition state probabilities, in general (no respect to month or season)
weatherTable <- table(train_data$transitionState)
weatherTable

probWetToWet = weatherTable['WetToWet'] / (weatherTable['WetToWet'] + weatherTable['WetToDry'])
probWetToWet

probDryToDry = weatherTable['DryToDry'] / (weatherTable['DryToDry'] + weatherTable['DryToWet'])
probDryToDry
```
This first basic generator takes an integer for how many days to simulate as input, and returns a list of rainfall amounts for each day. If the current state is dry, then if a random number between 0 and 1, generated by the runif() function, is below the probability of the dry to dry transition state, we keep the current state as dry, if not, we update the state to wet. Similarly, if the current state is wet, we keep it as wet or update it to dry depending on a random chance along with the probability calculated before. If the new state is dry, we record the rainfall as 0ml. If the new state is wet, we generate a random draw from the log-normal distribution as the rainfall amount. The rainfall amount is given by: 5.66*exp(rnorm(1)). We multiply by 5.66 as the expected value of exp(rnorm(1)) is around 1.648, and needs to generate rainfall with the average being the mean of the rainfall of the days when it does rain, which is 9.32ml in this case. 
```{r}
#Basic generator (No seasonal variation)

#calculated above
generateRainfallBasic <- function(genLength){
  currentState = "dry" # Years start with very little rain, so more likely to start dry
  rainAmountList <- c()
  for (i3 in 1:genLength){
    if (currentState == "dry"){
      if (runif(1) < probDryToDry){
        currentState = "dry"
      }
      else{
        currentState = "wet"
      }
    }
    else if (currentState == "wet"){
      if (runif(1) < probWetToWet){
        currentState = "wet"
      }
      else{
        currentState = "dry"
      }
    }
                                      #generating amount of rainfall if state is wet, else 0
    if (currentState == "wet"){
      rainAmount <- 5.66*exp(rnorm(1))
      rainAmountList <- c(rainAmountList, rainAmount)
    }
    else{
      rainAmountList <- c(rainAmountList, 0)
    }
  }
  return(rainAmountList)
}
```
Log-normal is used as it produces a very similar shape to the actual data. Importantly, it produces some results that are far off the bulk of the data, as found in the actual data. Originally, we used the exponential distribution, which did not produce this. As can be seen, similar means are produced from the simulated and actual rainfall data.
```{r}
#comparing log-normal against actual data, veeerryyyy close fit, will use log-normal for rainfall sim
par(mfrow=c(1,2))
p1 <- 5.66*exp(rnorm(732))
hist(p1, breaks = 30, xlim = c(0,120), ylim = c(0,400), main = "Simulated distribution", xlab = "Rainfall (ml)")

p2 <- train_data$Rainfall.amount..millimetres.[train_data$Rainfall.amount..millimetres.>1]
hist(p2, breaks = 30, xlim = c(0,120), ylim = c(0,400), main = "Actual distribution", xlab = "Rainfall (ml)")

mean(p1)
mean(p2)
```
Testing the basic generator, it appears that the amount of rainfall when it rained approximated the actual case very well. However, comparing 3761 days of simulated rainfall compared to actual rainfall, we can see that the actual rainfall comes more in waves, compared to the simualted rainfall here. This is because it rains more in winter months, meaning that the transition state probabilities are different for each month or season.
```{r, fig.height=8}
#Basic generator tests
testRainfall = generateRainfallBasic(3761)

par(mfrow=c(2,1))
hist(train_data$Rainfall.amount..millimetres.[train_data$Rainfall.amount..millimetres.>1 & train_data$Rainfall.amount..millimetres.<50], xlab = "Actual Rainfall (mm)", main = "Actual Rainfall Frequency Histogram")
hist(testRainfall[testRainfall > 1 & testRainfall <50], xlab = "Simulated Rainfall (mm)", main = "Simulated Rainfall Frequency Histogram")

par(mfrow=c(2,1))
barplot(train_data$Rainfall.amount..millimetres., ylim = c(0,80), main = "Original Data", ylab = "Rainfall (mm)", xlab = "Index")
barplot(testRainfall, ylim = c(0,80), main = "Simulated Data", ylab = "Rainfall (mm)", xlab = "Index")
```
Therefore, we need to change the probability for the state changes in the generator depending on the month of the year. To do this we created a data frame to count the number of occurences of transition states for each month. We initially filled the data frames all with zeroes, and increased the count by one for every occurence.
```{r}
#Calculates the transition probabilities for each month

transitonStatesMonthsFrame <- data.frame(list(rep(0, 12), list(rep(0, 12), list(rep(0, 12), list(rep(0, 12)))))) #Initialises 12x4 frame filled with zeroes (4 columns for each transition state, 12 rows for each month)
names(transitonStatesMonthsFrame) <- c('DryToDry', 'DryToWet', 'WetToDry', 'WetToWet')

#Makes the dataframe with the count of each transition state with each month
for (i4 in 1:dim(train_data)[1]){
  tempTransitionState <- train_data[i4, 'transitionState']
  tempMonth <- train_data[i4, 'Month'] 
  transitonStatesMonthsFrame[tempMonth, tempTransitionState] <- transitonStatesMonthsFrame[tempMonth, tempTransitionState]+1 # increase count of tempTransitionState for month tempMonth by 1
}
```

```{r}
head(transitonStatesMonthsFrame, 10)
```
We then create a copy of that data frame and calculate the probabilities just as before. This results in a data frame with the transition probabilities for each month.
```{r}
#Calculates the transition state probabilities for each month in the data frame
probTransitonStatesMonthsFrame <- transitonStatesMonthsFrame
for (i in 1:dim(transitonStatesMonthsFrame)[1]){
  
  probTransitonStatesMonthsFrame[i, 'DryToDry'] <- transitonStatesMonthsFrame[i, 'DryToDry'] / (transitonStatesMonthsFrame[i, 'DryToDry'] + transitonStatesMonthsFrame[i, 'DryToWet'])
  
  probTransitonStatesMonthsFrame[i, 'DryToWet'] <- transitonStatesMonthsFrame[i, 'DryToWet'] / (transitonStatesMonthsFrame[i, 'DryToDry'] + transitonStatesMonthsFrame[i, 'DryToWet'])
    
  probTransitonStatesMonthsFrame[i, 'WetToDry'] <- transitonStatesMonthsFrame[i, 'WetToDry'] / (transitonStatesMonthsFrame[i, 'WetToDry'] + transitonStatesMonthsFrame[i, 'WetToWet'])
    
  probTransitonStatesMonthsFrame[i, 'WetToWet'] <- transitonStatesMonthsFrame[i, 'WetToWet'] / (transitonStatesMonthsFrame[i, 'WetToDry'] + transitonStatesMonthsFrame[i, 'WetToWet'])
}
```

```{r}
head(probTransitonStatesMonthsFrame, 10)
```
Not only is it more likely to rain in some months than others, but there is also a different average amount of rainfall when it does rain. We tested to see if there's a different average rainfall for wet to wet vs dry to wet transition states, however, the resulting wilcoxon test did not show enough evidence to support this, so it was not added in the final model. A kruskal-wallis test of the average rainfall when it did rain (not total rainfall) for each month revealed sufficient evidence to conclude a difference for the month. The non-parametric tests were used as the rainfall data was not normally distributed.
```{r}
#testing average rainfall when its rains in each month, and for wettowet vs drytowet transitions.
test_w2w <- train_data$Rainfall.amount..millimetres.[train_data$transitionState == "WetToWet"]
test_d2w <- train_data$Rainfall.amount..millimetres.[train_data$transitionState == "DryToWet"]
mean(test_w2w)
mean(test_d2w)
wilcox.test(test_d2w, test_w2w)
#since resulting wilcox test p-value is 0.85, we conclude that theres no difference in rainfall depending on the transition state, and do not need to include it in our model.

test_rainfallPerMonth <- train_data[train_data$state == "wet",c(4,6)]
kruskal.test(Rainfall.amount..millimetres. ~ Month, data = test_rainfallPerMonth)
#p-val = 0.00016, therefore difference between average rainfall for each month

```
The average rainfall when it rained for each month was calculated, to be used in the more advanced generator. This was done by storing rainfall for wet days in a nested list and finding the mean.
```{r}
#calculating the mean rainfall when it rains for each month, to change how much it rains according to the generator later on. Limited to less than 60 mls as the dataset is not large enough for large rainfall amounts (such as 114ml in feburary) to not throw the mean off.
rainMonthData <- c()
for (i in 1:12){
  temp<- train_data$Rainfall.amount..millimetres.[train_data$state == "wet" & train_data$Month == i & train_data$Rainfall.amount..millimetres. < 60]
  rainMonthData <- c(rainMonthData, list(temp))
  rm(temp)
}

rainfallAvgMonth <- sapply(rainMonthData, mean)

```

```{r}
plot(c(1:12), rainfallAvgMonth, type = "l", xlab = "Month", ylab = "Average Rainfall (mm)", main = "Average rainfall for wet days for each month")
```

As can be seen, the transition states vary for each month.
```{r}
#How the transition state probabilities vary for each month
plot(probTransitonStatesMonthsFrame$DryToDry, ylim = c(0,1), xlab = "Month", main = "'dry to dry' transition state probability", type = 'l', ylab = "Probability")
plot(probTransitonStatesMonthsFrame$WetToWet, ylim = c(0,1), xlab = "Month", main = "'wet to wet' transition state probability", type = 'l', ylab = "Probability")
```
The new updated weathere generator uses the same old generator code for the most part, with a few changes. We now change the probability of the transitions depending on the month of the observation. This requires that we now input a data frame with a month column to calculate this. The rainfall generated on wet days is also updated to vary per month. 
```{r}

#Weather generator accounting  for seasonal variation of transition states or something i hope
#Yes this is just a spicy version of basic generator it's mostly the same in fact if i forget to even do this it is the same


generateRainfallSeasonal <- function(input){
  # input must be weather_data or a subset of weather_data
  currentState = "dry" #can make this into a random choice later
  rainAmountList <- c()
  for (i5 in 1:dim(input)[1]){
    if (currentState == "dry"){
      if (runif(1) < probTransitonStatesMonthsFrame[input[i5, 'Month'], 'DryToDry']){ #now inputs depending on the month of input
        currentState = "dry"
      }
      else{
        currentState = "wet"
      }
    }
    else if (currentState == "wet"){
      if (runif(1) < probTransitonStatesMonthsFrame[input[i5, 'Month'], 'WetToWet']){
        currentState = "wet"
      }
      else{
        currentState = "dry"
      }
    }
                                      #generating amount of rainfall if state is wet, else 0
    if (currentState == "wet"){
      
      #rainAmount <- 5.66*exp(rnorm(1)) #now log-normal dist, 5 used because is close to mean of weather_data's / the mean of what exp(rnorm(1)) is by default /// Old Version 
      rainAmount <- rainfallAvgMonth[input[i5, 'Month']]*exp(rnorm(1))/1.648 #average of exp(rnorm(1)) is ~1.648, so we divide by that so the average of each month will just be the actual average calculated from rainfallAvgMonth.
      
      rainAmountList <- c(rainAmountList, rainAmount)
    }
    else{
      rainAmountList <- c(rainAmountList, 0)
    }
  }
  return(rainAmountList)
}
```

```{r}
#testing code for seasonal generator
inputSeasonalRainfall <- dplyr::select(train_data, 'Year', 'Month', 'Day') #using existing train data's dates to input to function, instead of putting in just how many to generate

testSeasonalRainfall = generateRainfallSeasonal(inputSeasonalRainfall)
```
Simulated rainfall now follows a more seasonal pattern, as seen in the original data. Since we have used the original datas transition probabilities and rainfall averages, we expect that our model can give similar results to the original data.
```{r}
par(mfrow=c(2,1))
barplot(train_data$Rainfall.amount..millimetres., ylim = c(0,80), main = "Original Data", ylab = "Rainfall (mm)", xlab = "Index")
barplot(testSeasonalRainfall, ylim = c(0,80), main = "Simulated Data - seasonal", ylab = "Rainfall (mm)", xlab = "Index")
```


# Testing with sampling - Testing on a percentage of the data

To properly test a predictive algorithm, you cannot test the algorithm on the data that you trained it on. In a practical application, the algorithm would be predicting events that have not yet transpired, so would need to train on data from the past. To test the predictive power of the generator, we split 10.5 years of weather data (2010 - 2020) into two groups through random sampling, a training set (80%) and a testing set (20%). The training data was used to retrain the seasonal generator, entailing calculating new probabilities of transitioning between states for each month, and calculating the mean rainfall for each month. As the generator was retrained on only a portion of the data, it can be tested on the remainder 

```{r}
set.seed(100345)

sampID <- sample.int(nrow(train_data), size = 0.8*nrow(train_data), replace = FALSE)
train_data <- train_data[sampID,] # 80% of data for training
test_data <- train_data[-sampID,] # 20% for testing
```

```{r}
#code to calculate transition probabilities for each month (copied from earlier)
  # calculating the number of occurances of each trainsition state for eah month
transitonStatesMonthsFrame <- data.frame(list(rep(0, 12), list(rep(0, 12), list(rep(0, 12), list(rep(0, 12)))))) #initialising frame by creating 12x4 frame filled with zeroes
names(transitonStatesMonthsFrame) <- c('DryToDry', 'DryToWet', 'WetToDry', 'WetToWet') #name da columns

for (i4 in 1:dim(train_data)[1]){ #making dataframe with count of each transition state for each month
  tempTransitionState <- train_data[i4, 'transitionState']
  tempMonth <- train_data[i4, 'Month']
  transitonStatesMonthsFrame[tempMonth, tempTransitionState] <- transitonStatesMonthsFrame[tempMonth, tempTransitionState]+1
}


  #calculating the probabilites of each transition state for eachonth from the number of occurances 
probTransitonStatesMonthsFrame<- transitonStatesMonthsFrame

for (i in 1:dim(transitonStatesMonthsFrame)[1]){ #calculating transition probs for each month in df
  
  probTransitonStatesMonthsFrame[i, 'DryToDry'] <- transitonStatesMonthsFrame[i, 'DryToDry'] / (transitonStatesMonthsFrame[i, 'DryToDry'] + transitonStatesMonthsFrame[i, 'DryToWet'])
  
  probTransitonStatesMonthsFrame[i, 'DryToWet'] <- transitonStatesMonthsFrame[i, 'DryToWet'] / (transitonStatesMonthsFrame[i, 'DryToDry'] + transitonStatesMonthsFrame[i, 'DryToWet'])
    
  probTransitonStatesMonthsFrame[i, 'WetToDry'] <- transitonStatesMonthsFrame[i, 'WetToDry'] / (transitonStatesMonthsFrame[i, 'WetToDry'] + transitonStatesMonthsFrame[i, 'WetToWet'])
    
  probTransitonStatesMonthsFrame[i, 'WetToWet'] <- transitonStatesMonthsFrame[i, 'WetToWet'] / (transitonStatesMonthsFrame[i, 'WetToDry'] + transitonStatesMonthsFrame[i, 'WetToWet'])
}

# calucating the new average rainfall for each month
rainMonthData <- c()
for (i in 1:12){
  temp<- train_data$Rainfall.amount..millimetres.[train_data$state == "wet" & train_data$Month == i & train_data$Rainfall.amount..millimetres. < 60]
  rainMonthData <- c(rainMonthData, list(temp))
  rm(temp)
}

rainfallAvgMonth <- sapply(rainMonthData, mean)
```

The newly calibrated seasonal generator was then used to predict the testing data. This just involved generating simulated rainfall with the same number of observations as the tesing data (about 2.6 years of rainfall, or 20% of the original 10.5 years)

```{r}
#generate test data
testSeasonalRainfall20 = generateRainfallSeasonal(test_data) # generate a simulation with the same number of observations as test_data (20% of the total data)
```
```{r}
par(mfrow = c(2, 1))

barplot(testSeasonalRainfall20, ylab = "Rainfall (mm)", xlab = "index", main = "Simulated data")
barplot(test_data$Rainfall.amount..millimetres., ylab = "Rainfall (mm)", xlab  = "index", main = "Actual data")
```
```{r}
# Wilcoxon signed rank test
WT <- wilcox.test(testSeasonalRainfall20, test_data$Rainfall.amount..millimetres., paired=T)
print("Wilcoxon rank sum p-value")
WT$p.value
# paired student t test
TT <- t.test(testSeasonalRainfall20, test_data$Rainfall.amount..millimetres., paired=T)
print("t-test p-value")
TT$p.value
```
Looking at the barplots of the simulated data (top) and the actual data (bottom), the two do not appear to be similar. While the simulation looks believeable, random with periods of intense rainfall, it does not resemble the actual data specifically. To test the similarity of the two data sets, both the non-parametric Wilcoxon Signed Rank Test and the parametric Student T Test were performed. Both tests are paired as each simulated day is attempting to predic a specific actual day. A non-parametric test was used in conjunction with a parametric test as from the distribution of the rainfall is not normal (as seen by earlier histograms). Both tests returned a p-value less than 0.005 at a significance of 0.05, and as such it can be concluded that the simulated rainfall and the actual rainfall are different. 

# Using the data from the previous 10 years (2009-2018) to predict the weather for the next year (2019)

Predicting a randomly selected 20% of the weather data was unsuccesful, the simulated data and the actual data were significantly different, and by a comfortable margin. To try to increase the accuracy of the simulated data, we will increase the amount of training data and attempt to predict a specific year, instead of a randomly selected bunch of days. Increasing the amount of training data should increase the accuracy of the probabilites, and reduce the impact of outlying observation; and predicting a specific year should give the seasonal function of the generator more power. The next test will be predicting the rainfall of 2019 using 10 years of data from 2009-2018. To achieve this, the seasonal generator was retrained on all the rainfall data from those 10 years, and a simulation the lengh of one, non leap, year was generated. 

```{r}
train_data <- subset(weather_data, Year >= 2010)
train10_data <- subset(weather_data, Year >= 2009 & Year < 2019)
data_2019 <- subset(weather_data, Year == 2019)
```

```{r}
#code to calculate transition probabilities for each month (copied from earlier)

transitonStatesMonthsFrame <- data.frame(list(rep(0, 12), list(rep(0, 12), list(rep(0, 12), list(rep(0, 12)))))) #initialising frame by creating 12x4 frame filled with zeroes
names(transitonStatesMonthsFrame) <- c('DryToDry', 'DryToWet', 'WetToDry', 'WetToWet') #name da columns

for (i4 in 1:dim(train10_data)[1]){ #making dataframe with count of each transition state for each month
  tempTransitionState <- train10_data[i4, 'transitionState']
  tempMonth <- train10_data[i4, 'Month']
  transitonStatesMonthsFrame[tempMonth, tempTransitionState] <- transitonStatesMonthsFrame[tempMonth, tempTransitionState]+1
}


#also copied from earlier
probTransitonStatesMonthsFrame<- transitonStatesMonthsFrame
for (i in 1:dim(transitonStatesMonthsFrame)[1]){ #calculating transition probs for each month in df
  
  probTransitonStatesMonthsFrame[i, 'DryToDry'] <- transitonStatesMonthsFrame[i, 'DryToDry'] / (transitonStatesMonthsFrame[i, 'DryToDry'] + transitonStatesMonthsFrame[i, 'DryToWet'])
  
  probTransitonStatesMonthsFrame[i, 'DryToWet'] <- transitonStatesMonthsFrame[i, 'DryToWet'] / (transitonStatesMonthsFrame[i, 'DryToDry'] + transitonStatesMonthsFrame[i, 'DryToWet'])
    
  probTransitonStatesMonthsFrame[i, 'WetToDry'] <- transitonStatesMonthsFrame[i, 'WetToDry'] / (transitonStatesMonthsFrame[i, 'WetToDry'] + transitonStatesMonthsFrame[i, 'WetToWet'])
    
  probTransitonStatesMonthsFrame[i, 'WetToWet'] <- transitonStatesMonthsFrame[i, 'WetToWet'] / (transitonStatesMonthsFrame[i, 'WetToDry'] + transitonStatesMonthsFrame[i, 'WetToWet'])
}


set.seed(10356)

# get a testing 
monthList <- subset(weather_data, Year == 2019) # a year that isn't a leap year to get the month list, as generation algorithm only requires months
monthList <- monthList['Month']
testSeasonalRainfall10 <- generateRainfallSeasonal(monthList)
```

```{r, fig.height=9}
#compare generated year against 2019
par(mfrow = c(2,1))
barplot(testSeasonalRainfall10, xlab = "Index", ylab = "Rainfall (mm)", main = "Simulated Rainfall")
barplot(data_2019$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2019 Rainfall")
```
Looking at the simulated rainfall against the actual 2019 rainfall, the simulation has a very similar wet dry cycle to the actual data, even if the amount of rainfall during the wet seasons is not an accurate depiction. Aside from the exact amount of rain, the simulation looks to be a fairly good prediction of 2019. 

```{r}
# check other years for comparison
par(mfrow = c(3,2))
barplot(testSeasonalRainfall10, xlab = "Index", ylab = "Rainfall (mm)", main = "Simulated Rainfall")
year <- subset(weather_data, Year == 2015)
barplot(year$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2015 Rainfall")
year <- subset(weather_data, Year == 2008)
barplot(year$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2008 Rainfall")
year <- subset(weather_data, Year == 2015)
barplot(year$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2017 Rainfall")
year <- subset(weather_data, Year == 2007)
barplot(year$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2007 Rainfall")
year <- subset(weather_data, Year == 2013)
barplot(year$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2013 Rainfall")
rm(year)
```


# Examining for patterns
```{r}
# Creates a graph of difference in rainfall for years, weeks, months, years to see if there are any potential patterns.

# Creates a list of the weekly rainfall
RainfallWeekly <- data.frame("Rainfall (mm)", "Week")
colnames(RainfallWeekly) <- c("Rainfall (mm)", "Week")
RainfallWeekly$`Rainfall (mm)` <- as.numeric(RainfallWeekly$`Rainfall (mm)`)
RainfallWeekly$Week <- as.numeric(RainfallWeekly$Week)
week = 1
weekRain = 0
for(ii in c(1: nrow(weather_data))){
  weekRain = weekRain + weather_data[ii, 6] # rainfall amount for that row
  
  if(ii%%7 == 0){ # every 7th row
    RainfallWeekly[(ii/7), 1] <- weekRain # 1 row of RainfallWeekly created every 7 rows (1 weeks) - inserting rainfall total for that week
    RainfallWeekly[(ii/7), 2] <- week
    week = week + 1
    weekRain = 0 # clear total rainfall to prepare for next week
  }
}
```

```{r}
RainfallWeeklyDiff <- data.frame(c(1:(nrow(RainfallWeekly)-1)), c(1:(nrow(RainfallWeekly)-1))) # data frame with two columns, one less row than RainfallWeekly
colnames(RainfallWeeklyDiff) <- c("Rainfall diff (mm)", "Week")
RainfallWeeklyDiff$`Rainfall diff (mm)` <- diff(RainfallWeekly$`Rainfall (mm)`) # change in weeks
```
```{r, fig.height= 14}
# plot first 700 weeks first against the difference in rainfall, and then the rainfall per week
par(mfrow = c(4,1))
plot(RainfallWeeklyDiff[c(1:350), 2], RainfallWeeklyDiff[c(1:350), 1], xlab = "week", ylab = "change in rainfall (mm)", cex = 2, type = "b")
plot(RainfallWeekly[c(1:350), 2], RainfallWeekly[c(1:350), 1], xlab = "week", ylab = "rainfall (mm)", type = "l")
plot(RainfallWeeklyDiff[c(351:700), 2], RainfallWeeklyDiff[c(351:700), 1], xlab = "week", ylab = "change in rainfall (mm)", cex = 2, type = "b")
plot(RainfallWeekly[c(351:700), 2], RainfallWeekly[c(351:700), 1], xlab = "week", ylab = "rainfall (mm)", type = "l")

```

```{r, fig.height= 14}
# plot second 700 weeks first against the difference in rainfall, and then the rainfall per week
par(mfrow = c(4,1))
plot(RainfallWeeklyDiff[c(701:1050), 2], RainfallWeeklyDiff[c(701:1050), 1], xlab = "week", ylab = "change in rainfall (mm)", cex = 2, type = "b")
plot(RainfallWeekly[c(701:1050), 2], RainfallWeekly[c(701:1050), 1], xlab = "week", ylab = "rainfall (mm)", type = "l")
plot(RainfallWeeklyDiff[c(1051:1414), 2], RainfallWeeklyDiff[c(1051:1414), 1], xlab = "week", ylab = "change in rainfall (mm)", cex = 2, type = "b")
plot(RainfallWeekly[c(1051:1414), 2], RainfallWeekly[c(1051:1414), 1], xlab = "week", ylab = "rainfall (mm)", type = "l")
```

```{r}
rainSort_2019 <- data_2019$Rainfall.amount..millimetres.
# qqplot before removing 'dry' days
qqnorm(rainSort_2019, pch = 1, frame = F, main = "Normal Q-Q Plot of Rainfall 2019 (including dry days)")
qqline(rainSort_2019, col = "red", lwd = 2)
rainSort_2019 <- rainSort_2019[which(rainSort_2019 != 0)]
# qqplot after removing 'dry' days
qqnorm(rainSort_2019, pch = 1, frame = F, main = "Normal Q-Q Plot of Rainfall 2019 (excluding dry days)")
qqline(rainSort_2019, col = "red", lwd = 2)
hist(rainSort_2019, breaks = 50)
# data is not normally distributed
rm(rainSort_2019)
```


# Wilcoxon signed rank test on the data for 2019

```{r}
rain2019 <- subset(weather_data, Year == 2019)
length(rain2019$Rainfall.amount..millimetres.)
length(testSeasonalRainfall10)

```
```{r}
# function to return the sum of ranks of difference (w+ and w-) that are part of the Wilcoxon signed rank calculations
returnRanks <- function(simulated, actual){
  diffs <- (simulated - actual)
  diffs <- diffs[diffs != 0]
  posDifs <- which(diffs > 0)
  negDiffs <- which(diffs < 0)
  rank <- rank(abs(diffs))
  rankPosDiff <- sum(rank[posDifs])
  rankNegDiff <- sum(rank[negDiffs]) 
  return(c(rankPosDiff, rankNegDiff))
}

```


```{r}

table(rain2019$Month)
# Since there are two days missing from October and December, we will have to find the days and remove them from our simulated results.
table(rain2019$Day)
# one month is missing a day 5, and another is missing a day 19 (both 11 when should be 12)/
temp <- subset(rain2019, Day == 5)
temp$Month # 5th of October missing
temp <- subset(rain2019, Day == 19)
temp$Month # 19th of December missing
rm(temp)
```
```{r}
# to perform Wilcoxon Signed Rank test must have paired data, so remove those extra dates from testSeasonalRainfall10
# 2019 is a non leap year

which(rain2019$date == "4-10-2019") # find what row the day before 5-10-2019 is
# thereforer 5-10-2019 would be row 278 (277+1)
which(rain2019$date == "18-12-2019") # find what row the day before 5-10-2019 is
# thereforer 5-10-2019 would be row 353 (351+2). Add two as both 5th october and 19th december are missing

simRainfall2019 <- testSeasonalRainfall10 # remove day 278 and day 353 data from testSeasonalRainfall10
```

```{r}
set.seed(102343656)

# get a testing 
monthList <- subset(weather_data, Year == 2019) # a year that isn't a leap year to get the month list, as generation algorithm only requires months
monthList <- monthList['Month']
testSeasonalRainfall10 <- generateRainfallSeasonal(monthList)
simRainfall2019 <- testSeasonalRainfall10 # remove day 278 and day 353 data from testSeasonalRainfall10
```

```{r}
# test of testSeasonalRainfall10 against 2019 rainfall (testSeasonalRainfall10 was simulation of 2019 rainfall)
wilcox.test(rain2019$Rainfall.amount..millimetres., simRainfall2019, paired = T, alternative = "t", conf.int = T, conf.level = 0.95)

# the p-value is 0.04918,indicating that it is likely that there is a significant difference between the simulated data and the actual data. This means that one set of data was consistently and significantly larger than the other

# manual calculation of Wilcoxon signed rank values 

sumRanks <- returnRanks(simRainfall2019, rain2019$Rainfall.amount..millimetres.)
sumRanks[1] # rankPosDiff ( sum of the ranks of the positive differences)
sumRanks[2] # rankNegDiff (sum of the ranks of the negative differrences)

# rankPosDiff (the sum of the ranks of the differences where the simulated data is greater than the actual) is 7414. rankNegDiff (the sum of the ranks of the the differences where the actual is greater than the simulated) is 5147. rankPosDiff is quite a bit larger than rankNegDiff
```
```{r}
# to confirm the results of the first Wilcoson signed rank test, repeat with 3 different sets of simulated rainfall
set.seed(12345)

# using month probabilites generate one years worth of data 
monthList <- subset(weather_data, Year == 2011) # a year that isn't a leap year to get the month list, as generation algorithm only requires months
monthList <- monthList['Month']
testSeasonalRainfall10 <- generateRainfallSeasonal(monthList)

simRainfall2019 <- testSeasonalRainfall10[-c(278, 353)] # remove day 278 and day 353 data from testSeasonalRainfall10

wilcox.test(rain2019$Rainfall.amount..millimetres., simRainfall2019, paired = T, alternative = "t", conf.int = T, conf.level = 0.95)

# The p-value is 0.1981, indiciating that there is not a significant difference between the simulated data and the actual data

# manual calculation of Wilcoxon signed rank values 
sumRanks <- returnRanks(simRainfall2019, rain2019$Rainfall.amount..millimetres.)
sumRanks[1] # rankPosDiff ( sum of the ranks of the positive differences)
sumRanks[2] # rankNegDiff (sum of the ranks of the negative differrences)

```
```{r}
set.seed(347876)

# using month probabilites generate one years worth of data 
monthList <- subset(weather_data, Year == 2011) # a year that isn't a leap year to get the month list, as generation algorithm only requires months
monthList <- monthList['Month']
testSeasonalRainfall10 <- generateRainfallSeasonal(monthList)

simRainfall2019 <- testSeasonalRainfall10[-c(278, 353)] # remove day 278 and day 353 data from testSeasonalRainfall10

wilcox.test(rain2019$Rainfall.amount..millimetres., simRainfall2019, paired = T, alternative = "t", conf.int = T, conf.level = 0.95)

# manual calculation of Wilcoxon signed rank values 
sumRanks <- returnRanks(simRainfall2019, rain2019$Rainfall.amount..millimetres.)
sumRanks[1] # rankPosDiff ( sum of the ranks of the positive differences)
sumRanks[2] # rankNegDiff (sum of the ranks of the negative differrences)

```
```{r}
set.seed(3456789)
# using month probabilites generate one years worth of data 
monthList <- subset(weather_data, Year == 2011) # a year that isn't a leap year to get the month list, as generation algorithm only requires months
monthList <- monthList['Month']
testSeasonalRainfall10 <- generateRainfallSeasonal(monthList)

simRainfall2019 <- testSeasonalRainfall10[-c(278, 353)] # remove day 278 and day 353 data from testSeasonalRainfall10

wilcox.test(rain2019$Rainfall.amount..millimetres., simRainfall2019, paired = T, alternative = "t", conf.int = T, conf.level = 0.95)


# manual calculation of Wilcoxon signed rank values 
sumRanks <- returnRanks(simRainfall2019, rain2019$Rainfall.amount..millimetres.)
sumRanks[1] # rankPosDiff ( sum of the ranks of the positive differences)
sumRanks[2] # rankNegDiff (sum of the ranks of the negative differrences)

```

```{r}
# looking at the four total simulations created, there is generally no significant different between the simulated rainfall and the actual rainfall. 
# However looking at rankPosDiff and rankNegDiff calculated for each (the sum of the ranks of the positive and negative differences between the simulated and actual data respectively), the simulated rainfall was consistently larger than the actual data 
# The reason for this is likely because 2019 had a very small amount of rainfall compared to the rest of the years.
sum(train10_data$Rainfall.amount..millimetres.)/10 # /10 to get average of 10 years of rain data
sum(rain2019$Rainfall.amount..millimetres.)
```



```{r}
median(simRainfall2019)
median(rain2019$Rainfall.amount..millimetres.)

# given the number of dry days, it makes sense that the median's would be very similar in the Wilcoxon Signed Rank test
# To perform the Wilcoxon Signed Rank test we remove those dates from testSeasonalRainfall10
# 2019 is a non leap year so February will have 28 days
#October 5th and December 19th are missing, so we remove them
month_result <- which(rain2019$date == "4-10-2019" | rain2019$date=="18-12-2019")
simRainfall2019 <- testSeasonalRainfall10[-c(month_result[1]+1, month_result[2]+1)]

# Test of testSeasonalRainfall10 against 2019 rainfall (testSeasonalRainfall10 was simulation of 2019 rainfall)
wilcox.test(simRainfall2019, rain2019$Rainfall.amount..millimetres., paired = T, alternative = "t")

# Since the p-value is relatively high, it can be concluded that there is no significant diference between the simulated 2019 data and the actual 2019 data. 
# While the simulation may not be an accurate prediction of 2019 (as seen in the barplots), the simulation was also not logically flawed, as there is not a significant difference between the median of the simulation and the median of the actual.
#Furthermore, a qucik comparison of the medians in the Wilcoxon Signed Rank test shows that (as expected) they are also very similar.
cat("Median of actual and simulated rainfall respectively: ", median(rain2019$Rainfall.amount..millimetres.), median(simRainfall2019))
rm(simRainfall2019)
```


```{r}
# looking at 2013 data (which had a larger than average amount of rain)

rain2013 <- subset(weather_data, Year == 2013)
simRainfall2013 <- generateRainfallSeasonal(monthList)
wilcox.test(simRainfall2013, rain2013$Rainfall.amount..millimetres., paired = T, conf.int = T, conf.level = 0.95)

par(mfrow = c(2,1))
barplot(simRainfall2013, xlab = "Index", ylab = "Rainfall (mm)", main = "Simulated Rainfall")
barplot(rain2013$Rainfall.amount..millimetres., xlab = "Index", ylab = "Rainfall (mm)", main = "2013 Rainfall")

diffs <- (simRainfall2013 - rain2013$Rainfall.amount..millimetres.)
diffs <- diffs[diffs != 0]
posDifs <- which(diffs > 0)
negDiffs <- which(diffs < 0)
rank <- rank(abs(diffs))
rankPosDiff <- sum(rank[posDifs])
rankNegDiff <- sum(rank[negDiffs]) 

rankPosDiff
rankNegDiff

mean(diffs)
```


